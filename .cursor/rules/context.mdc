# FairPlay NIL Platform Context

You are an expert full-stack web developer working on the FairPlay NIL platform - a React + FastAPI application for Name, Image, and Likeness (NIL) deal management.

## ðŸ—ï¸ Architecture Overview

**Frontend:** React 18 + Vite + Chakra UI  
**Backend:** FastAPI + PostgreSQL (Supabase)  
**Deployment:** Vercel (frontend) + Render (backend)  
**Error Tracking:** Sentry integration  
**Environment:** Multi-environment configuration system

## ðŸ“ Critical Project Structure

```
fairplay-nil/
â”œâ”€â”€ frontend/                 # React + Vite app
â”‚   â”œâ”€â”€ src/
â”‚   â”‚   â”œâ”€â”€ config/
â”‚   â”‚   â”‚   â””â”€â”€ environment.js    # âš ï¸ CRITICAL: Environment configuration
â”‚   â”‚   â”œâ”€â”€ components/
â”‚   â”‚   â”œâ”€â”€ pages/
â”‚   â”‚   â”œâ”€â”€ context/
â”‚   â”‚   â””â”€â”€ main.jsx             # âš ï¸ CRITICAL: App entry (Sentry setup)
â”‚   â”œâ”€â”€ tests/                  # âš ï¸ CRITICAL: Playwright E2E tests
â”‚   â”‚   â”œâ”€â”€ smoke.spec.js        # Basic application tests
â”‚   â”‚   â”œâ”€â”€ deal-wizard.spec.js  # Deal Wizard functionality tests
â”‚   â”‚   â””â”€â”€ setup-verification.spec.js # Setup verification tests
â”‚   â”œâ”€â”€ scripts/
â”‚   â”‚   â””â”€â”€ debug-with-playwright.js # Interactive debugging script
â”‚   â”œâ”€â”€ playwright.config.js     # âš ï¸ CRITICAL: Playwright configuration
â”‚   â”œâ”€â”€ vercel.json              # âš ï¸ CRITICAL: Vercel deployment config
â”‚   â””â”€â”€ package.json
â”œâ”€â”€ backend/                    # FastAPI app
â”‚   â”œâ”€â”€ app/
â”‚   â”‚   â”œâ”€â”€ middleware/
â”‚   â”‚   â”‚   â””â”€â”€ error_handling.py # âš ï¸ CRITICAL: Backend error handling
â”‚   â”‚   â””â”€â”€ main.py
â”‚   â””â”€â”€ migrations/
â”œâ”€â”€ .github/workflows/
â”‚   â””â”€â”€ playwright.yml          # âš ï¸ CRITICAL: CI/CD with Playwright testing
â””â”€â”€ To-do-before-bug-fixing.md  # âš ï¸ CRITICAL: Implementation status
```

## ðŸš€ Deployment Workflow

### Primary Deployment (Recommended)
```bash
# 1. Make changes
# 2. Test locally: npm run dev
# 3. Run Playwright tests: npm run test:e2e
# 4. Build test: npm run build
# 5. Commit & push:
git add . && git commit -m "message" && git push origin main
# 6. GitHub Actions runs Playwright tests
# 7. Vercel auto-deploys from GitHub (only if tests pass)
```

### Enhanced Testing Workflow
```bash
# Pre-deployment testing
npm run test:e2e              # Run all tests
npm run test:e2e:headed       # Run with browser visible
npm run test:e2e:debug        # Step-through debugging
npm run debug:playwright      # Interactive debugging session
npm run test:e2e:report       # View test reports
```

### Production Deployment Process
**âš ï¸ IMPORTANT**: We use GitHub integration with Vercel for automatic deployments:
1. **Make changes** to the codebase
2. **Test locally** with `npm run dev` in frontend directory
3. **Commit changes** with descriptive messages
4. **Push to GitHub** (`git push origin main`)
5. **Vercel automatically deploys** from GitHub integration
6. **No manual Vercel CLI deployment needed**

### Environment-Specific Builds
```bash
npm run build:staging     # Staging environment
npm run build:production  # Production environment
npm run build            # Default build
```

## âš™ï¸ Environment Configuration System

### âœ… ALWAYS USE THIS PATTERN:
```javascript
// âœ… CORRECT: Use centralized environment config
import { getConfig, errorTrackingConfig } from './src/config/environment';

// âŒ WRONG: Don't use direct import.meta.env access
// import.meta.env.VITE_API_URL
```

### Environment Variables (Vercel Dashboard)
```bash
VITE_API_URL=https://fairplay-nil-backend.onrender.com
VITE_SENTRY_DSN=https://8a759dc24e0d183c942867eb9d1eadc6@o4509759316426752.ingest.us.sentry.io/4509759319572480
VITE_APP_VERSION=1.0.0
VITE_BUILD_TIME=auto-generated
```

## ðŸ”§ Critical Implementation Patterns

### Frontend Error Handling
```javascript
// âœ… Graceful error handling pattern
try {
  // your code
} catch (error) {
  console.warn("Graceful error handling:", error);
  // App continues working
}
```

### Backend Error Handling
- **Already implemented** in `backend/app/middleware/error_handling.py`
- **No additional try/catch needed** in route handlers
- **Automatic error logging** and sanitization

### Sentry Integration
- **Dynamic imports** in `main.jsx` to prevent crashes
- **Environment-specific** configuration
- **Graceful degradation** if Sentry fails

## ðŸ“‹ Validation Commands

```bash
npm run validate:env    # Check environment config
npm run lint           # Code quality
npm run test           # Run unit tests
npm run test:e2e       # Run Playwright E2E tests
npm run test:e2e:headed # Run tests with browser visible
npm run test:e2e:debug # Step-through test debugging
npm run debug:playwright # Interactive debugging session
npm run build          # Test build
```

## âš ï¸ Critical Warnings

### âŒ DON'T:
- Use direct `import.meta.env` access
- Modify `vercel.json` without understanding routing
- Deploy without testing build first
- Skip environment validation
- Use static Sentry imports (use dynamic imports)

### âœ… DO:
- Use centralized environment configuration
- Run Playwright tests before deployment (`npm run test:e2e`)
- Use GitHub auto-deployment for reliability
- Monitor Sentry for errors after deployment
- Follow established error handling patterns
- Use interactive debugging for complex issues (`npm run debug:playwright`)
- Check test reports after CI/CD runs

## ðŸ” Troubleshooting Quick Reference

### Blank Website Issues:
1. Check console for JavaScript errors
2. Verify Sentry initialization in `main.jsx`
3. Check Vercel deployment logs
4. Validate environment variables

### Build Failures:
1. Run `npm run validate:env`
2. Check for missing dependencies
3. Verify environment configuration
4. Run `npm run test:e2e` to check for test failures
5. Check Playwright test reports for specific issues

### Deployment Failures:
1. Check Vercel dashboard for errors
2. Verify `vercel.json` configuration
3. Ensure all environment variables are set
4. Check GitHub Actions for Playwright test failures
5. Review test reports in `frontend/playwright-report/`
6. Run `npm run test:e2e:headed` locally to reproduce issues

## ðŸŽ¯ Technical Preferences

- Use PascalCase for React component names (e.g. MyComponent.jsx)
- Use kebab-case for file names (e.g. my-component.jsx)
- Leverage React Context API for state management (AuthContext, DealContext)
- Use React Router for client-side routing
- Always add loading and error states to data fetching components
- Implement error handling and error logging
- Use semantic HTML elements where possible
- Use Chakra UI components consistently for UI
- Follow the user's requirements carefully & to the letter
- Always write correct, up-to-date, bug-free, fully functional and working, secure, performant and efficient code
- Focus on readability over being performant
- Fully implement all requested functionality
- Leave NO todo's, placeholders or missing pieces in the code
- Be sure to reference file names
- Be concise. Minimize any other prose
- If you think there might not be a correct answer, you say so. If you do not know the answer, say so instead of guessing

## ðŸŽ­ Playwright E2E Testing System

### **Critical Testing Infrastructure**
- **Multi-browser testing**: Chrome, Firefox, Safari, Mobile Chrome, Mobile Safari
- **Automated CI/CD**: GitHub Actions runs tests before deployment
- **Interactive debugging**: `npm run debug:playwright` for real-time debugging
- **Test coverage**: 40 tests across 5 browsers covering critical user flows

### **Test Categories**
```javascript
// Smoke Tests (tests/smoke.spec.js)
- Homepage loading and navigation
- Authentication flow testing
- Console error detection
- Cross-browser compatibility

// Deal Wizard Tests (tests/deal-wizard.spec.js)
- Form interactions and validation
- Step navigation and state management
- Error handling and recovery
- User flow completion

// Setup Verification (tests/setup-verification.spec.js)
- Basic functionality verification
- Browser interaction testing
- Configuration validation
```

### **Debugging Commands**
```bash
# Run all tests
npm run test:e2e

# Interactive debugging (recommended for complex issues)
npm run debug:playwright

# Step-through debugging
npm run test:e2e:debug

# Visual debugging (see browser)
npm run test:e2e:headed

# View test reports
npm run test:e2e:report
```

### **Test Writing Guidelines**
```javascript
// âœ… CORRECT: Use descriptive test names and proper error handling
test('should handle deal wizard form submission', async ({ page }) => {
  await page.goto('/deal-wizard');
  await page.fill('[name="dealType"]', 'endorsement');
  await page.click('[data-testid="submit"]');
  await expect(page.locator('.success-message')).toBeVisible();
});

// âŒ WRONG: Avoid generic test names and missing error handling
test('test form', async ({ page }) => {
  await page.goto('/form');
  // Missing assertions and error handling
});
```

### **Error Detection Features**
- **Console error monitoring**: Automatic capture of JavaScript errors
- **Network failure detection**: Failed API calls and slow responses
- **Visual regression testing**: Screenshot comparison on failures
- **Performance monitoring**: Page load times and memory usage
- **Cross-browser issues**: Browser-specific problem detection

## ðŸ“Š Implementation Status

### âœ… Completed (Critical Infrastructure):
- **Backend Error Handling** - Comprehensive middleware with secure logging
- **Environment Configuration** - Multi-environment system with Vercel integration
- **Sentry Integration** - Dynamic imports with graceful error handling
- **Deployment Pipeline** - GitHub â†’ Vercel auto-deployment working
- **Production Configuration** - All environment variables and settings configured
- **Playwright E2E Testing** - Complete testing infrastructure with CI/CD integration

### ðŸ”„ Remaining (Optional):
- Database Performance Indexes
- ESLint Configuration
- Additional test scenarios for specific user flows

The platform is now production-ready with robust error handling, monitoring, and deployment infrastructure.    
    
- Leave NO todo's, placeholders or missing pieces in the code.
- Be sure to reference file names.
- Be concise. Minimize any other prose.
- If you think there might not be a correct answer, you say so. If you do not know the answer, say so instead of guessing.    
    